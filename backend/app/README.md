
# FastAPI Backend

> [!NOTE]
> This `README` will be updated.

---

## Getting Started

> [!NOTE]
> At this point, it is assumed that `poetry` has been installed on your device.

Create an environment file, and populate the keys found in `.env.sample` with the values specific for you.

```bash
touch ./.env
```

Navigate to this directory and enter into a poetry shell.

```bash
poetry shell
```

Poetry is used to start the backend server. Currently, there is only one command that can start the server.

```bash
poetry run dev
```

---

## Endpoint Documentation

Endpoints should be documented in `EndpointDocs.yaml` using [OpenAPI specification](https://swagger.io/docs/specification/basic-structure/).

---

## Scripts

### Generate Mock Data

A python script has been created to generate mock data. This is runnable using poetry.

```bash
poetry run mock
```

### Populate MongoDB with Actual Data

Ensure that docker with MongoDB is configured and running before proceeding. If not already set up, follow the setup instructions [here](https://github.com/Wilsven/healthhub-content-optimization/tree/clustering_sx/docker)

#### Steps to Populate Data

1. Prepare Data Files
    - Place the following files in the `app/data` folder:
        - `merged_data.parquet`: This file can be generated by running the [Kedro pipeline](https://github.com/Wilsven/healthhub-content-optimization/tree/main?tab=readme-ov-file#running-kedro) for data processing.
        - `nomic-embed-text-v1.5_neo4j_edges.pkl` and `nomic-embed-text-v1.5_neo4j_predicted_clusters.pkl`: These files can be obtained by running the `clustering_evaluation.ipynb` in [clustering branch](https://github.com/Wilsven/healthhub-content-optimization/tree/clustering/content-optimization/notebooks). Alternatively, the data is temporarily stored in [Google Drive](https://drive.google.com/drive/folders/1FLg0omAB_zD20JUNkAQkjyi5OkNSDdXK) until the kedro pipeline for clustering is set up.

2. Ensure Clean Database
    - Before populating MongoDB, ensure that the `storage` database is cleared before each run to avoid data duplication. This can be done in the MongoDB Compass UI.

3. Run the Command
    ```bash
    poetry run data
    ```
