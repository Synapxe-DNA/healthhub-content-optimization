{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d8ca6",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "b635fb18e9551590",
   "metadata": {},
   "source": [
    "import math\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tiktoken"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81e560944b1e6587",
   "metadata": {},
   "source": [
    "## Load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0b51052c8c63cff",
   "metadata": {},
   "source": [
    "# Load dataframe from `data` directory\n",
    "merged_data = pd.read_parquet(\"../data/merged_data.parquet\")\n",
    "\n",
    "display(merged_data)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a766863682e337e",
   "metadata": {},
   "source": [
    "df_keep = merged_data[~merged_data[\"to_remove\"]]\n",
    "\n",
    "\n",
    "display(df_keep)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f83caa7654abac5",
   "metadata": {},
   "source": [
    "relevant_categories = [\n",
    "    \"cost-and-financing\",\n",
    "    \"live-healthy-articles\",\n",
    "    \"diseases-and-conditions\",\n",
    "    \"medical-care-and-facilities\",\n",
    "    \"support-group-and-others\",\n",
    "]\n",
    "\n",
    "df_keep = df_keep[df_keep[\"content_category\"].isin(relevant_categories)]\n",
    "\n",
    "display(df_keep)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b5c7cb502f3a9d",
   "metadata": {},
   "source": [
    "df_extracted = df_keep[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"content_name\",\n",
    "        \"title\",\n",
    "        \"article_category_names\",\n",
    "        \"full_url\",\n",
    "        \"friendly_url\",\n",
    "        \"category_description\",\n",
    "        \"content_category\",\n",
    "        \"content_body\",\n",
    "        \"pr_name\",\n",
    "        # \"has_table\",\n",
    "        # \"has_image\",\n",
    "        # \"related_sections\",\n",
    "        # \"extracted_tables\",\n",
    "        # \"extracted_links\",\n",
    "        # \"extracted_headers\",\n",
    "        # \"extracted_img_alt_text\",\n",
    "        \"extracted_content_body\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(df_extracted)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bfe23d28acd976ba",
   "metadata": {},
   "source": [
    "## Calculate total number of Tokens using `tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c06c6f645497c5a",
   "metadata": {},
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def calculate_word_count(text):\n",
    "    sentences = []\n",
    "    words = []\n",
    "\n",
    "    # Compile regex to detect punctuations\n",
    "    regex = re.compile(\"[%s]\" % re.escape(string.punctuation))\n",
    "\n",
    "    # Remove all hyperlinks\n",
    "    filtered_text = re.sub(r\"https?:\\/\\/[^\\s]+\", \"\", text)\n",
    "\n",
    "    # Split the extracted text by the newline delimiter\n",
    "    lines = filtered_text.split(\"\\n\")\n",
    "    # Track the sentences in the text\n",
    "    for line in lines:\n",
    "        partial_sentences = re.split(r\"[.!?]\", line)\n",
    "        for sentence in partial_sentences:\n",
    "            sentences.append(sentence.strip())\n",
    "\n",
    "    # Track the words in the text\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split(\" \")\n",
    "        for word in sentence_words:\n",
    "            word = regex.sub(\"\", word.strip())\n",
    "            words.append(word)\n",
    "\n",
    "    # Filter for empty strings\n",
    "    filtered_words = list(filter(lambda x: len(x) > 0, words))\n",
    "\n",
    "    # Count the number of words\n",
    "    num_words = len(filtered_words)\n",
    "    return num_words\n",
    "\n",
    "\n",
    "df_extracted.loc[:, \"num_content_tokens\"] = df_extracted[\n",
    "    \"extracted_content_body\"\n",
    "].apply(lambda x: num_tokens_from_string(x))\n",
    "\n",
    "df_extracted.loc[:, \"word_count\"] = df_extracted[\"extracted_content_body\"].apply(\n",
    "    lambda x: calculate_word_count(x)\n",
    ")\n",
    "\n",
    "display(  # noqa: F821\n",
    "    df_extracted.sort_values(by=[\"num_content_tokens\"], ascending=False)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51cfbc191d283120",
   "metadata": {},
   "source": [
    "total_tokens_across_articles = df_extracted[\"num_content_tokens\"].sum()\n",
    "print(f\"Total Tokens across articles: {total_tokens_across_articles}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d4d3f9b23a36db0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.histogram(df_extracted, x=\"num_content_tokens\", nbins=80)\n",
    "fig.update_layout(\n",
    "    title_text=\"Token Count distribution for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Token Count\",\n",
    "    yaxis_title_text=\"Count\",\n",
    "    bargap=0.1,\n",
    ")\n",
    "# fig.add_vline(x=lower_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "# fig.add_vline(x=upper_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c7f135d16abf6a1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "print(\n",
    "    df_extracted[\"num_content_tokens\"].quantile(\n",
    "        [0.001, 0.021, 0.159, 0.5, 0.841, 0.977, 0.999]\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ca3e2271af03058",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_extracted.loc[:, \"log_num_tokens\"] = np.log(df_extracted[\"num_content_tokens\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58bfff913bc1d994",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.histogram(df_extracted, x=\"log_num_tokens\", nbins=80)\n",
    "fig.update_layout(\n",
    "    title_text=\"Log Token Count distribution for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Token Count\",\n",
    "    yaxis_title_text=\"Count\",\n",
    "    bargap=0.1,\n",
    ")\n",
    "# fig.add_vline(x=lower_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "# fig.add_vline(x=upper_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b79f43602163f2b1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.box(df_extracted, x=\"log_num_tokens\", color=\"content_category\")\n",
    "fig.update_layout(\n",
    "    title_text=\"Box Plot for Log Token Count for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Log Token Count\",\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14baea00d4361d6e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_hpb = df_extracted[df_extracted[\"pr_name\"] == \"Health Promotion Board\"]\n",
    "\n",
    "display(df_hpb.sort_values(by=[\"num_content_tokens\"], ascending=False))  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6222527312777d65",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.histogram(df_hpb, x=\"num_content_tokens\", nbins=80)\n",
    "fig.update_layout(\n",
    "    title_text=\"Token Count distribution for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Token Count\",\n",
    "    yaxis_title_text=\"Count\",\n",
    "    bargap=0.1,\n",
    ")\n",
    "# fig.add_vline(x=lower_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "# fig.add_vline(x=upper_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98c999a9bd989a62",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.histogram(df_hpb, x=\"log_num_tokens\", nbins=80)\n",
    "fig.update_layout(\n",
    "    title_text=\"Token Count distribution for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Token Count\",\n",
    "    yaxis_title_text=\"Count\",\n",
    "    bargap=0.1,\n",
    ")\n",
    "# fig.add_vline(x=lower_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "# fig.add_vline(x=upper_threshold, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec034b6a0f4aa84a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.box(df_hpb, x=\"log_num_tokens\", color=\"content_category\")\n",
    "fig.update_layout(\n",
    "    title_text=\"Box Plot for Log Token Count for Extracted Article Content\",\n",
    "    xaxis_title_text=\"Log Token Count\",\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84ca028b39120f19",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "fig = px.scatter(\n",
    "    df_hpb,\n",
    "    x=\"num_content_tokens\",\n",
    "    y=\"word_count\",\n",
    "    color=\"content_category\",\n",
    "    trendline=\"ols\",\n",
    "    trendline_scope=\"overall\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=\"Scatterplot of Token Count with respect to Word Count\",\n",
    "    xaxis_title_text=\"Token Count\",\n",
    "    yaxis_title_text=\" Word Count\",\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8153fe26d3ae16a2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "results = px.get_trendline_results(fig)\n",
    "print(results)\n",
    "\n",
    "results.px_fit_results.iloc[0].summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2b36c87ff4cc755",
   "metadata": {},
   "source": [
    "Based on the statistics above, 1 token ~= 0.75 words. We will use this measure going forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34648fa32a1e7d",
   "metadata": {},
   "source": [
    "## Expected Cost Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325b441cf8a27fd",
   "metadata": {},
   "source": [
    "### Cost of OpenAI models"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb7e819f78e28786",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "## Costs per 1000 tokens\n",
    "models_costs = {\n",
    "    \"gpt-3.5-turbo-0125\": {\"inputs\": 0.0005, \"outputs\": 0.0015},\n",
    "    \"gpt-4o\": {\"inputs\": 0.005, \"outputs\": 0.015},\n",
    "    \"gpt-4o-mini\": {\"inputs\": 0.15 / 1000, \"outputs\": 0.60 / 1000},\n",
    "    \"gpt-3.5-turbo-0301\": {\"inputs\": 0.002, \"outputs\": 0.002},\n",
    "    \"gpt-3.5-turbo-instruct\": {\"inputs\": 0.0015, \"outputs\": 0.002},\n",
    "    \"gpt-3.5-turbo-0613-16k\": {\"inputs\": 0.003, \"outputs\": 0.004},\n",
    "    \"gpt-3.5-turbo-1106\": {\"inputs\": 0.001, \"outputs\": 0.002},\n",
    "}\n",
    "\n",
    "print(models_costs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d4f4238ce97e8a8",
   "metadata": {},
   "source": [
    "#### Number of Agents, Max Number of Similar Articles, Percentage of articles to optimise/harmonise"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ec0537341722de1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "## Optimisation\n",
    "# Meta Desc Quality Eval, Title Quality Eval, Content Quality Eval, Researcher, Meta Desc Optimiser, Title Optimiser, Content Guidelines, Writing Guidelines\n",
    "# Percentage of articles to optimise\n",
    "percentage_to_optimise = 0.4\n",
    "\n",
    "## Harmonisation\n",
    "# Researcher, Compiler, Meta Desc Optimiser, Title Optimiser, Content Guidelines, Writing Guidelines\n",
    "# Number of similar articles (max. 5)\n",
    "similar_articles_count = 5\n",
    "\n",
    "# Percentage of articles to combine/harmonise\n",
    "percentage_to_harmonise = 0.3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2fa5d5c44daad1c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Generated evaluations\n",
    "generated_evaluation_tokens = 200  # Approx. 150 words for generated text from evaluating meta desc, title and content quality each respectively\n",
    "\n",
    "# Title and Meta Desc tokens\n",
    "title_tokens = 25  # Approx. 70 characters / 16 words\n",
    "meta_desc_tokens = 75  # Approx 50 words\n",
    "\n",
    "# Generated Output Multiplier (with respect to article tokens)\n",
    "keypoints_generated_multiplier = 1.1\n",
    "compiled_articles_multiplier = (\n",
    "    0.8  # An estimate of the generated article as compared to compiled articles\n",
    ")\n",
    "content_guidelines_multiplier = 1.25\n",
    "writing_guidelines_multiplier = content_guidelines_multiplier * 1.25\n",
    "\n",
    "## Prompt Tokens\n",
    "evaluation_prompt_tokens = 200  # Approx. 150 words for evaluating meta desc, title and content quality respectively\n",
    "researcher_prompt_tokens = 400  # Approx. 300 words for instructing researcher\n",
    "compiler_prompt_tokens = 400  # Approx. 300 words for instructing compiler\n",
    "guidelines_prompt_tokens = 600  # Approx. 450 words for guidelines\n",
    "meta_desc_prompt_tokens = 200  # Approx. 150 words for prompt instructions\n",
    "title_prompt_tokens = 200  # Approx. 150 words for prompt instructions\n",
    "\n",
    "\n",
    "# USD to SGD Conversion\n",
    "usd_to_sgd = 1.35\n",
    "\n",
    "tokens_dict = {\n",
    "    \"percentage_to_optimise\": percentage_to_optimise,\n",
    "    \"similar_articles_count\": similar_articles_count,\n",
    "    \"percentage_to_harmonise\": percentage_to_harmonise,\n",
    "    \"title_tokens\": title_tokens,\n",
    "    \"meta_desc_tokens\": meta_desc_tokens,\n",
    "    \"keypoints_generated_multiplier\": keypoints_generated_multiplier,\n",
    "    \"compiled_articles_multiplier\": compiled_articles_multiplier,\n",
    "    \"content_guidelines_multiplier\": content_guidelines_multiplier,\n",
    "    \"writing_guidelines_multiplier\": writing_guidelines_multiplier,\n",
    "    \"evaluation_prompt_tokens\": evaluation_prompt_tokens,\n",
    "    \"researcher_prompt_tokens\": researcher_prompt_tokens,\n",
    "    \"compiler_prompt_tokens\": compiler_prompt_tokens,\n",
    "    \"guidelines_prompt_tokens\": guidelines_prompt_tokens,\n",
    "    \"meta_desc_prompt_tokens\": meta_desc_prompt_tokens,\n",
    "    \"title_prompt_tokens\": title_prompt_tokens,\n",
    "    \"usd_to_sgd\": usd_to_sgd,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec60130da0b465ba",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def calculate_tokens_optimisation(\n",
    "    article_tokens: int, params: dict[str, int] = tokens_dict\n",
    ") -> int:\n",
    "    # Prompt Tokens\n",
    "    evaluation_prompt_tokens = params.get(\"evaluation_prompt_tokens\", 200)\n",
    "    researcher_prompt_tokens = params.get(\"researcher_prompt_tokens\", 400)\n",
    "    guidelines_prompt_tokens = params.get(\"guidelines_prompt_tokens\", 600)\n",
    "    meta_desc_prompt_tokens = params.get(\"meta_desc_prompt_tokens\", 200)\n",
    "    title_prompt_tokens = params.get(\"title_prompt_tokens\", 200)\n",
    "\n",
    "    # Generated Tokens\n",
    "    title_tokens = params.get(\"title_tokens\", 25)\n",
    "    meta_desc_tokens = params.get(\"meta_desc_tokens\", 75)\n",
    "    generated_evaluation_tokens = params.get(\"generated_evaluation_tokens\", 200)\n",
    "\n",
    "    # Multipliers\n",
    "    keypoints_generated_multiplier = params.get(\"keypoints_generated_multiplier\", 0.5)\n",
    "    content_guidelines_multiplier = params.get(\"content_guidelines_multiplier\", 1.25)\n",
    "    writing_guidelines_multiplier = params.get(\"writing_guidelines_multiplier\", 1.5)\n",
    "\n",
    "    # Meta Desc, Title and Content Quality Evaluation - Token Calculation\n",
    "    evaluation_input_tokens = (\n",
    "        evaluation_prompt_tokens * 3 + article_tokens + title_tokens + meta_desc_tokens\n",
    "    )\n",
    "    evaluation_output_tokens = generated_evaluation_tokens * 3\n",
    "\n",
    "    # Researcher -> Keypoints - Token Calculation\n",
    "    researcher_input_tokens = researcher_prompt_tokens + article_tokens\n",
    "    researcher_output_tokens = article_tokens * keypoints_generated_multiplier\n",
    "\n",
    "    # Content Guidelines - Token Calculation\n",
    "    content_guidelines_input_tokens = (\n",
    "        guidelines_prompt_tokens + researcher_output_tokens\n",
    "    )\n",
    "    content_guidelines_output_tokens = article_tokens * content_guidelines_multiplier\n",
    "\n",
    "    # Writing Guidelines - Token Calculation\n",
    "    writing_guidelines_input_tokens = (\n",
    "        guidelines_prompt_tokens + content_guidelines_output_tokens\n",
    "    )\n",
    "    writing_guidelines_output_tokens = article_tokens * writing_guidelines_multiplier\n",
    "\n",
    "    # Title Optimisation - Token Calculation\n",
    "    title_optimisation_input_tokens = (\n",
    "        title_prompt_tokens + writing_guidelines_output_tokens\n",
    "    )\n",
    "    title_optimisation_output_tokens = title_tokens\n",
    "\n",
    "    # Meta Desc Optimisation - Token Calculation\n",
    "    meta_desc_input_tokens = meta_desc_prompt_tokens + writing_guidelines_output_tokens\n",
    "    meta_desc_output_tokens = meta_desc_tokens\n",
    "\n",
    "    # Total Tokens Calculation\n",
    "    total_input_tokens = math.ceil(\n",
    "        evaluation_input_tokens\n",
    "        + researcher_input_tokens\n",
    "        + content_guidelines_input_tokens\n",
    "        + writing_guidelines_input_tokens\n",
    "        + title_optimisation_input_tokens\n",
    "        + meta_desc_input_tokens\n",
    "    )\n",
    "    total_output_tokens = math.ceil(\n",
    "        evaluation_output_tokens\n",
    "        + researcher_output_tokens\n",
    "        + content_guidelines_output_tokens\n",
    "        + writing_guidelines_output_tokens\n",
    "        + title_optimisation_output_tokens\n",
    "        + meta_desc_output_tokens\n",
    "    )\n",
    "\n",
    "    return total_input_tokens, total_output_tokens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9614382612a63350",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def calculate_optimisation_costs(\n",
    "    article_tokens: int,\n",
    "    model: str = \"gpt-3.5-turbo-0125\",\n",
    "    params: dict[str, int] = tokens_dict,\n",
    ") -> int:\n",
    "    usd_to_sgd = params.get(\"usd_to_sgd\", 1.35)\n",
    "\n",
    "    inputs, outputs = calculate_tokens_optimisation(article_tokens, params)\n",
    "    optimisation_cost = (\n",
    "        (\n",
    "            inputs * models_costs[model][\"inputs\"]\n",
    "            + outputs * models_costs[model][\"outputs\"]\n",
    "        )\n",
    "        / 1000\n",
    "        * usd_to_sgd\n",
    "    )\n",
    "\n",
    "    return optimisation_cost"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "658ddd6c1827b8b0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "model = \"gpt-3.5-turbo-0125\"\n",
    "col = f\"optimise_costs_{model}\"\n",
    "df_extracted[col] = df_extracted[\"num_content_tokens\"].apply(\n",
    "    lambda x: calculate_optimisation_costs(x, model, tokens_dict)\n",
    ")\n",
    "\n",
    "display(df_extracted)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c15b987571afc963",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "col = f\"optimise_costs_{model}\"\n",
    "df_extracted[col] = df_extracted[\"num_content_tokens\"].apply(\n",
    "    lambda x: calculate_optimisation_costs(x, model, tokens_dict)\n",
    ")\n",
    "\n",
    "display(df_extracted)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab9a8638cbda984d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "model = \"gpt-3.5-turbo-0301\"\n",
    "col = f\"optimise_costs_{model}\"\n",
    "df_extracted[col] = df_extracted[\"num_content_tokens\"].apply(\n",
    "    lambda x: calculate_optimisation_costs(x, model, tokens_dict)\n",
    ")\n",
    "\n",
    "display(df_extracted)  # noqa: F821"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd6c48e98f75b65e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_extracted.to_excel(\"../data/articles_optimisation_costs.xlsx\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1dcb7f4288a90a72",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def calculate_tokens_harmonisation(\n",
    "    article_tokens_list,\n",
    "    params: dict[str, int] = tokens_dict,\n",
    ") -> int:\n",
    "    # Prompt Tokens\n",
    "    researcher_prompt_tokens = params.get(\"researcher_prompt_tokens\", 400)\n",
    "    compiler_prompt_tokens = params.get(\"compiler_prompt_tokens\", 400)\n",
    "    guidelines_prompt_tokens = params.get(\"guidelines_prompt_tokens\", 600)\n",
    "    meta_desc_prompt_tokens = params.get(\"meta_desc_prompt_tokens\", 200)\n",
    "    title_prompt_tokens = params.get(\"title_prompt_tokens\", 200)\n",
    "\n",
    "    # Generated Tokens\n",
    "    title_tokens = params.get(\"title_tokens\", 25)\n",
    "    meta_desc_tokens = params.get(\"meta_desc_tokens\", 75)\n",
    "\n",
    "    # Multipliers\n",
    "    keypoints_generated_multiplier = params.get(\"keypoints_generated_multiplier\", 0.5)\n",
    "    compiled_articles_multiplier = params.get(\"compiled_articles_multiplier\", 0.8)\n",
    "    content_guidelines_multiplier = params.get(\"content_guidelines_multiplier\", 1.25)\n",
    "    writing_guidelines_multiplier = params.get(\"writing_guidelines_multiplier\", 1.5)\n",
    "\n",
    "    researcher_input_tokens = 0\n",
    "    researcher_output_tokens = 0\n",
    "\n",
    "    # Researcher -> Keypoints\n",
    "    for i in range(len(article_tokens_list)):\n",
    "        researcher_input_tokens += researcher_prompt_tokens + article_tokens_list[i]\n",
    "        researcher_output_tokens += (\n",
    "            article_tokens_list[i] * keypoints_generated_multiplier\n",
    "        )\n",
    "\n",
    "    # Compiler\n",
    "    compiler_input_tokens = compiler_prompt_tokens + researcher_output_tokens\n",
    "    compiler_output_tokens = researcher_output_tokens\n",
    "\n",
    "    # Content Guidelines\n",
    "    content_guidelines_input_tokens = guidelines_prompt_tokens + compiler_output_tokens\n",
    "    content_guidelines_output_tokens = (\n",
    "        sum(article_tokens_list)\n",
    "        * compiled_articles_multiplier\n",
    "        * content_guidelines_multiplier\n",
    "    )\n",
    "\n",
    "    # Writing Guidelines\n",
    "    writing_guidelines_input_tokens = (\n",
    "        guidelines_prompt_tokens + content_guidelines_output_tokens\n",
    "    )\n",
    "    writing_guidelines_output_tokens = (\n",
    "        sum(article_tokens_list)\n",
    "        * compiled_articles_multiplier\n",
    "        * writing_guidelines_multiplier\n",
    "    )\n",
    "\n",
    "    # Title Optimisation\n",
    "    title_optimisation_input_tokens = (\n",
    "        title_prompt_tokens + writing_guidelines_output_tokens\n",
    "    )\n",
    "    title_optimisation_output_tokens = title_tokens\n",
    "\n",
    "    # Meta Desc Optimisation\n",
    "    meta_desc_input_tokens = meta_desc_prompt_tokens + writing_guidelines_output_tokens\n",
    "    meta_desc_output_tokens = meta_desc_tokens\n",
    "\n",
    "    # Total\n",
    "    total_input_tokens = math.ceil(\n",
    "        researcher_input_tokens\n",
    "        + compiler_input_tokens\n",
    "        + content_guidelines_input_tokens\n",
    "        + writing_guidelines_input_tokens\n",
    "        + title_optimisation_input_tokens\n",
    "        + meta_desc_input_tokens\n",
    "    )\n",
    "    total_output_tokens = math.ceil(\n",
    "        researcher_output_tokens\n",
    "        + compiler_output_tokens\n",
    "        + content_guidelines_output_tokens\n",
    "        + writing_guidelines_output_tokens\n",
    "        + title_optimisation_output_tokens\n",
    "        + meta_desc_output_tokens\n",
    "    )\n",
    "    return total_input_tokens, total_output_tokens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18ee8d9c26da9d96",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def calculate_costs(tokens_array, model, params: dict[str, int] = tokens_dict):\n",
    "    usd_to_sgd = params.get(\"usd_to_sgd\", 1.35)\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(tokens_array)\n",
    "    # print(tokens_array)\n",
    "\n",
    "    optimization_size = round(percentage_to_optimise * tokens_array.size)\n",
    "    # print(optimization_size)\n",
    "\n",
    "    harmonisation_size = int(\n",
    "        (percentage_to_harmonise * tokens_array.size // similar_articles_count + 1)\n",
    "        * similar_articles_count\n",
    "    )\n",
    "    # print(harmonisation_size)\n",
    "\n",
    "    optimization_tokens_array = tokens_array[:optimization_size]\n",
    "    harmonisation_tokens_array = tokens_array[\n",
    "        optimization_size : optimization_size + harmonisation_size\n",
    "    ].reshape(-1, similar_articles_count)\n",
    "    # print(len(harmonisation_tokens_array))\n",
    "\n",
    "    optimisation_cost = 0\n",
    "    for i in range(optimization_tokens_array.shape[0]):\n",
    "        inputs, outputs = calculate_tokens_optimisation(optimization_tokens_array[i])\n",
    "        optimisation_cost += (\n",
    "            (\n",
    "                inputs * models_costs[model][\"inputs\"]\n",
    "                + outputs * models_costs[model][\"outputs\"]\n",
    "            )\n",
    "            / 1000\n",
    "            * usd_to_sgd\n",
    "        )  # Return cost in SGD\n",
    "\n",
    "    print(f\"Optimisation cost: {optimisation_cost}\")\n",
    "\n",
    "    harmonisation_cost = 0\n",
    "    for i in range(harmonisation_tokens_array.shape[0]):\n",
    "        inputs, outputs = calculate_tokens_harmonisation(harmonisation_tokens_array[i])\n",
    "        harmonisation_cost += (\n",
    "            (\n",
    "                inputs * models_costs[model][\"inputs\"]\n",
    "                + outputs * models_costs[model][\"outputs\"]\n",
    "            )\n",
    "            / 1000\n",
    "            * usd_to_sgd\n",
    "        )  # Return cost in SGD\n",
    "\n",
    "    print(f\"Harmonisation cost: {harmonisation_cost}\")\n",
    "\n",
    "    cost = optimisation_cost + harmonisation_cost\n",
    "\n",
    "    return cost"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d7ff77989d57998",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def calculate_average_costs(tokens_array, model, runs=30):\n",
    "    costs = []\n",
    "    for i in range(runs):\n",
    "        cost = calculate_costs(tokens_array, model)\n",
    "        costs.append(cost)\n",
    "\n",
    "    avg_cost = sum(costs) / runs\n",
    "    print(tokens_array.shape[0])\n",
    "    print(f\"Average cost: {avg_cost}\")\n",
    "    avg_cost_per_article = avg_cost / (\n",
    "        (percentage_to_optimise + percentage_to_harmonise) * tokens_array.shape[0]\n",
    "    )\n",
    "    print(f\"Average cost Per article: {avg_cost_per_article}\")\n",
    "\n",
    "    return avg_cost"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b51a1212d6f6a58d",
   "metadata": {},
   "source": [
    "### All articles"
   ]
  },
  {
   "cell_type": "code",
   "id": "9af988492c50845a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "tokens_array = np.copy(df_extracted[\"num_content_tokens\"].to_numpy())\n",
    "print(tokens_array)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c07625c3cf974be",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "calculate_costs(tokens_array, model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89c3ee41001e54eb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "calculate_average_costs(\n",
    "    tokens_array, model=\"gpt-3.5-turbo-0301\"\n",
    ")  # gpt-3.5-turbo-0125, gpt-4o-mini, gpt-4o"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e97b2736eb9af5bd",
   "metadata": {},
   "source": [
    "### HPB Articles"
   ]
  },
  {
   "cell_type": "code",
   "id": "f35bebae94234aff",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "hpb_tokens_array = np.copy(df_hpb[\"num_content_tokens\"].to_numpy())\n",
    "print(tokens_array)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea008173869c518b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "calculate_costs(hpb_tokens_array, model=\"gpt-3.5-turbo-0301\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef085c2bd7a3c8a2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "calculate_average_costs(\n",
    "    hpb_tokens_array, model=\"gpt-3.5-turbo-0301\"\n",
    ")  # gpt-3.5-turbo-0125, gpt-4o-mini, gpt-4o"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89253b6da3ed2962",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
