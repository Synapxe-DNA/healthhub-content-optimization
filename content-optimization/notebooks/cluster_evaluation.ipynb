{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import DriverError, Neo4jError\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, v_measure_score\n",
    "\n",
    "load_dotenv(r\"..\\conf\\local\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MODEL_NAME: str = \"all-mpnet-base-v2\"\n",
    "CONTRIBUTOR: str = \"Health Promotion Board\"\n",
    "\n",
    "# specify content_category. input 'all' if running across all categories\n",
    "CONTENT_CATEGORY: str = \"live-healthy-articles\"\n",
    "\n",
    "# adjust accordingly\n",
    "THRESHOLD: float = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_GROUNDTRUTH_PATH = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"01_raw\",\n",
    "    \"Synapxe Content Prioritisation - Live Healthy_020724.xlsx\",\n",
    ")\n",
    "\n",
    "DATA_FOLDER_PATH = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"07_model_output\",\n",
    "    f\"{CONTENT_CATEGORY}\",\n",
    ")\n",
    "\n",
    "INPUT_EMBEDDING_NEO4J_PATH = os.path.join(\n",
    "    DATA_FOLDER_PATH,\n",
    "    f\"{CONTENT_CATEGORY}_{MODEL_NAME}_embeddings_neo4j.pkl\",\n",
    ")\n",
    "\n",
    "OUTPUT_PREDICTED_CLUSTER_PATH = os.path.join(\n",
    "    DATA_FOLDER_PATH,\n",
    "    f\"{CONTENT_CATEGORY}__{MODEL_NAME}_predicted_clusters.csv\",\n",
    ")\n",
    "\n",
    "OUTPUT_CLUSTER_METRICS_PATH = os.path.join(\n",
    "    DATA_FOLDER_PATH,\n",
    "    f\"{CONTENT_CATEGORY}_compiled_model_variation_metrics.csv\",\n",
    ")\n",
    "\n",
    "NEO4J_FOLDER_PATH = os.path.join(\n",
    "    DATA_FOLDER_PATH,\n",
    "    \"neo4j\",\n",
    ")\n",
    "\n",
    "if not os.path.exists(NEO4J_FOLDER_PATH):\n",
    "    os.makedirs(NEO4J_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged_df data\n",
    "merged_data_df = catalog.load(\"merged_data\")  # noqa\n",
    "\n",
    "# load ground truth data\n",
    "ground_truth = pd.read_excel(INPUT_GROUNDTRUTH_PATH, sheet_name=2)\n",
    "ground_truth = ground_truth[ground_truth[\"Owner\"].str.contains(CONTRIBUTOR)]\n",
    "ground_truth = ground_truth[[\"Page Title\", \"Combine Group ID\", \"URL\"]]\n",
    "ground_truth = ground_truth[ground_truth[\"Combine Group ID\"].notna()]\n",
    "\n",
    "# Extract id from merged_data_df to ground truth\n",
    "ground_truth = pd.merge(\n",
    "    ground_truth, merged_data_df, how=\"inner\", left_on=\"URL\", right_on=\"full_url\"\n",
    ")\n",
    "ground_truth = ground_truth[[\"id\", \"Page Title\", \"URL\", \"Combine Group ID\"]]\n",
    "ground_truth.rename(columns={\"Combine Group ID\": \"ground_truth_cluster\"}, inplace=True)\n",
    "\n",
    "print(ground_truth.shape)\n",
    "ground_truth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings file\n",
    "with open(INPUT_EMBEDDING_NEO4J_PATH, \"rb\") as f:\n",
    "    articles = pickle.load(f)\n",
    "\n",
    "# merge with ground truth\n",
    "articles_df = pd.merge(\n",
    "    articles,\n",
    "    ground_truth,\n",
    "    how=\"inner\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\",\n",
    ")\n",
    "\n",
    "vector_columns = [col for col in articles_df.columns if \"vector\" in col]\n",
    "for col in vector_columns:\n",
    "    articles_df[col] = articles_df[col].apply(lambda x: x.tolist())\n",
    "\n",
    "print(articles_df.shape)\n",
    "articles_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"neo4j://localhost:7687\"\n",
    "username = os.getenv(\"neo4j_username\")\n",
    "password = os.getenv(\"neo4j_password\")\n",
    "# driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "NEO4J = {\n",
    "    \"uri\": uri,\n",
    "    \"auth\": (username, password),\n",
    "    \"database\": CONTENT_CATEGORY,  # create this database in neo4j first\n",
    "}\n",
    "\n",
    "# Test connection\n",
    "with GraphDatabase.driver(**NEO4J) as driver:\n",
    "    try:\n",
    "        driver.verify_connectivity()\n",
    "        print(\"Connection estabilished.\")\n",
    "    except (DriverError, Neo4jError) as exception:\n",
    "        print(exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = articles_df.to_dict(orient=\"records\")\n",
    "documents[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def clear_db(tx):\n",
    "    logging.info(\"Clearing database\")\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "\n",
    "def create_graph_nodes(tx, doc):\n",
    "    # logging.info(\"Create nodes\")\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "    CREATE (d:Article {\n",
    "        id: $id,\n",
    "        title: $title,\n",
    "        url: $url,\n",
    "        content: $content,\n",
    "        meta_desc: $meta_description,\n",
    "        vector_body: $vector_body,\n",
    "        vector_title: $vector_title,\n",
    "        vector_category: $vector_category,\n",
    "        vector_desc: $vector_desc,\n",
    "        ground_truth: $ground_truth\n",
    "    })\"\"\",\n",
    "        id=doc[\"id\"],\n",
    "        title=doc[\"title\"],\n",
    "        url=doc[\"full_url\"],\n",
    "        content=doc[\"content\"],\n",
    "        meta_description=doc[\"meta_description\"],\n",
    "        vector_title=doc[\"vector_title\"],\n",
    "        vector_category=doc[\"vector_article_category_names\"],\n",
    "        vector_desc=doc[\"vector_category_description\"],\n",
    "        vector_body=doc[\"vector_extracted_content_body\"],\n",
    "        ground_truth=doc[\"ground_truth_cluster\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def create_sim_edges(tx, threshold):\n",
    "    logging.info(\"Create edges\")\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "    MATCH (a:Article), (b:Article)\n",
    "    WHERE a.id < b.id\n",
    "    WITH a, b, gds.similarity.cosine(a.vector_body, b.vector_body) AS similarity\n",
    "    WHERE similarity > $threshold\n",
    "    CREATE (a)-[:SIMILAR {similarity: similarity}]->(b)\n",
    "    \"\"\",\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "\n",
    "def drop_graph_projection(tx):\n",
    "    result = tx.run(\n",
    "        \"\"\"\n",
    "    CALL gds.graph.exists('articleGraph')\n",
    "    YIELD exists\n",
    "    RETURN exists\n",
    "    \"\"\"\n",
    "    )\n",
    "    if result.single()[\"exists\"]:\n",
    "        tx.run(\"CALL gds.graph.drop('articleGraph')\")\n",
    "\n",
    "\n",
    "def create_graph_proj(tx):\n",
    "    # logging.info(\"Create projection\")\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "           CALL gds.graph.project(\n",
    "            'articleGraph',\n",
    "            'Article',\n",
    "            {\n",
    "                SIMILAR: {\n",
    "                    properties: 'similarity'\n",
    "                }\n",
    "            }\n",
    "           )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def detect_community(tx):\n",
    "    # logging.info(\"Detect community\")\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        CALL gds.louvain.write(\n",
    "        'articleGraph',\n",
    "        {\n",
    "            writeProperty: 'community'\n",
    "        }\n",
    "        )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def return_community(tx):\n",
    "    query = \"\"\"\n",
    "        MATCH (a:Article)\n",
    "        RETURN a.community AS cluster, collect(a.title) AS articles\n",
    "        ORDER BY cluster\n",
    "        \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [record for record in result]\n",
    "\n",
    "\n",
    "def return_pred_cluster(tx):\n",
    "    query = \"\"\"\n",
    "        MATCH (a:Article)\n",
    "        RETURN a.id, a.title, a.url, a.community AS cluster\n",
    "        ORDER BY a.community\n",
    "        \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [record for record in result]\n",
    "\n",
    "\n",
    "def count_articles(tx):\n",
    "    query = \"\"\"\n",
    "        MATCH (a:Article)\n",
    "        RETURN a.community AS cluster, count(a) AS articleCount\n",
    "        ORDER BY cluster\n",
    "        \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [record for record in result]\n",
    "\n",
    "\n",
    "def return_by_cluster(tx):\n",
    "    \"\"\"Return only clusters with more than one article\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    MATCH (n)\n",
    "    WITH n.community AS cluster, collect(n.title) AS titles, count(n) AS count\n",
    "    WHERE count > 1\n",
    "    RETURN cluster, titles\n",
    "    ORDER BY cluster\n",
    "        \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [record for record in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(**NEO4J) as driver:\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(clear_db)  # Clear the database\n",
    "        for doc in documents:\n",
    "            session.execute_write(create_graph_nodes, doc)\n",
    "        session.execute_write(create_sim_edges, THRESHOLD)\n",
    "        session.execute_write(drop_graph_projection)\n",
    "        session.execute_write(create_graph_proj)\n",
    "        session.execute_write(detect_community)\n",
    "        records = session.execute_read(return_community)\n",
    "        pred_cluster = session.execute_read(return_pred_cluster)\n",
    "        articles_count = session.execute_read(count_articles)\n",
    "        cluster_articles = session.execute_read(return_by_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cluster_df = pd.DataFrame(\n",
    "    pred_cluster, columns=[\"id\", \"title\", \"url\", \"pred_cluster\"]\n",
    ")\n",
    "pred_cluster_df.to_csv(OUTPUT_PREDICTED_CLUSTER_PATH)\n",
    "\n",
    "cluster_article_count = pd.DataFrame(\n",
    "    articles_count, columns=[\"pred_cluster_number\", \"article_count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.merge(\n",
    "    articles_df, pred_cluster_df, how=\"inner\", left_on=\"id\", right_on=\"id\"\n",
    ")\n",
    "\n",
    "results_df = results_df[\n",
    "    [\"id\", \"Page Title\", \"URL\", \"ground_truth_cluster\", \"pred_cluster\"]\n",
    "]\n",
    "results_df[\"ground_truth_cluster\"] = results_df[\"ground_truth_cluster\"].astype(int)\n",
    "\n",
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_match(results_df):\n",
    "    pred_cluster_labels = results_df.groupby(\"pred_cluster\")[\"id\"].apply(set).to_list()\n",
    "    ground_cluster_labels = (\n",
    "        results_df.groupby(\"ground_truth_cluster\")[\"id\"].apply(set).to_list()\n",
    "    )\n",
    "    complete_match = [s for s in pred_cluster_labels if s in ground_cluster_labels]\n",
    "\n",
    "    return len(complete_match)\n",
    "\n",
    "\n",
    "def fill_single(series):\n",
    "    max_val = series.max()\n",
    "    fill_in_val = max_val\n",
    "    filled_series = series.copy()\n",
    "    for idx in series[series.isna()].index:\n",
    "        filled_series.at[idx] = fill_in_val + 1\n",
    "        fill_in_val += 1\n",
    "    return filled_series.to_list()\n",
    "\n",
    "\n",
    "def compute_vmeasure(results_df):\n",
    "    ground_truth_labels = fill_single(results_df[\"ground_truth_cluster\"])\n",
    "    predicted_labels = fill_single(results_df[\"pred_cluster\"])\n",
    "    homogeneity = homogeneity_score(ground_truth_labels, predicted_labels)\n",
    "    completeness = completeness_score(ground_truth_labels, predicted_labels)\n",
    "    v_measure = v_measure_score(ground_truth_labels, predicted_labels)\n",
    "\n",
    "    return homogeneity, completeness, v_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = cluster_article_count[cluster_article_count[\"article_count\"] > 1][\n",
    "    \"article_count\"\n",
    "].min()\n",
    "max_count = cluster_article_count[\"article_count\"].max()\n",
    "num_clusters = (cluster_article_count[\"article_count\"] != 1).sum()\n",
    "unclustered_count = (cluster_article_count[\"article_count\"] == 1).sum()\n",
    "\n",
    "exact_match = get_exact_match(results_df)\n",
    "homogeneity, completeness, v_measure = compute_vmeasure(results_df)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [MODEL_NAME],\n",
    "        \"Threshold\": [THRESHOLD],\n",
    "        \"Exact cluster match\": [exact_match],\n",
    "        \"Homogeneity\": [round(homogeneity, 4)],\n",
    "        \"Completeness\": [round(completeness, 4)],\n",
    "        \"V-measure\": [round(v_measure, 4)],\n",
    "        \"Number of clusters\": [num_clusters],\n",
    "        \"Min cluster size\": [min_count],\n",
    "        \"Max cluster size\": [max_count],\n",
    "        \"Number of articles not clustered\": [unclustered_count],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_CLUSTER_METRICS_PATH):\n",
    "    metrics_df = pd.read_csv(OUTPUT_CLUSTER_METRICS_PATH, index_col=0)\n",
    "else:\n",
    "    metrics_df = pd.DataFrame()\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, data], axis=0)\n",
    "metrics_df.to_csv(OUTPUT_CLUSTER_METRICS_PATH)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (n)-[r]->(m)\n",
    "RETURN n.title AS node_1, m.title AS node_2,\n",
    "r.similarity AS edge_weight,\n",
    "n.ground_truth AS node_1_ground_truth,\n",
    "m.ground_truth AS node_2_ground_truth,\n",
    "n.community AS node_1_pred_cluster,\n",
    "m.community AS node_2_pred_cluster,\n",
    "n.title AS node_1_title,\n",
    "m.title AS node_2_title\n",
    "\"\"\"\n",
    "# nodes with no relationship\n",
    "query_2 = \"\"\"MATCH (n)\n",
    "WHERE NOT EXISTS ((n)--())\n",
    "RETURN n.title AS node_title,\n",
    "n.ground_truth AS node_ground_truth,\n",
    "n.community AS node_community,\n",
    "n.meta_desc AS node_meta_desc\n",
    "\"\"\"\n",
    "with GraphDatabase.driver(**NEO4J) as driver:\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        data = pd.DataFrame(results.data())\n",
    "        results_2 = session.run(query_2)\n",
    "        data_2 = pd.DataFrame(results_2.data())\n",
    "\n",
    "data[\"node_1\"] = data[\"node_1\"].astype(str)\n",
    "data[\"node_2\"] = data[\"node_2\"].astype(str)\n",
    "# data = data.dropna(subset=['node_2'])\n",
    "\n",
    "data_2[\"node_community\"] = \"\"\n",
    "\n",
    "# save nodes and edges of clustered and unclustered (single nodes) data for visualisation\n",
    "data.to_csv(os.path.join(NEO4J_FOLDER_PATH, f\"{MODEL_NAME}_neo4j_clustered_data.csv\"))\n",
    "data_2.to_csv(\n",
    "    os.path.join(NEO4J_FOLDER_PATH, f\"{MODEL_NAME}_neo4j_unclustered_data.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep edges if 2 nodes are from same cluster\n",
    "edges_in_same_cluster = data[data[\"node_1_pred_cluster\"] == data[\"node_2_pred_cluster\"]]\n",
    "edges = edges_in_same_cluster[[\"node_1\", \"node_2\", \"edge_weight\"]]\n",
    "with open(\n",
    "    os.path.join(NEO4J_FOLDER_PATH, f\"{MODEL_NAME}_neo4j_edges.pkl\"), \"wb\"\n",
    ") as file:\n",
    "    pickle.dump(edges, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cluster_dict = [\n",
    "    {\"cluster\": e[\"cluster\"], \"titles\": e[\"titles\"]} for e in cluster_articles\n",
    "]\n",
    "with open(\n",
    "    os.path.join(NEO4J_FOLDER_PATH, f\"{MODEL_NAME}_neo4j_pred_cluster.pkl\"), \"wb\"\n",
    ") as file:\n",
    "    pickle.dump(pred_cluster_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
