# Content Optimization for HealthHub

This repository contains the content optimization for HealthHub.

## Installation

Create a virtual environment using `conda` (recommended) and install dependencies:

```bash
# Create a virtual environment
conda create -n <VENV_NAME> python=3.12 -y
conda activate <VENV_NAME>

# Install dependencies
pip install -r requirements.txt
```

## File Structure

The exploratory/experimental code for content optimization is stored in the [`notebooks/`](notebooks) folder.

- [`artifacts/`](artifacts): contains the output of the exploratory/experimental code

    * [`notebooks/`](artifacts/notebooks): contains experiments generated by [`papermill`](https://papermill.readthedocs.io/en/latest/)

    * [`outputs/`](artifacts/outputs): contains the experiment outputs (i.e. confusion matrices) generated by [`papermill`](https://papermill.readthedocs.io/en/latest/)

        * [`statistical_vector_based_embeddings_similarity_scores.xlsx`](artifacts/outputs/statistical_vector_based_embeddings_similarity_scores.xlsx): contains the similarity scores of experiments generated from Statistical Vector-based Embedding techniques.

- [`data/`](data): contains the data used in the exploratory/experimental code

    * [`healthhub_small/`](data/healthhub_small): contains a small subset of Health Hub raw data

    * [`healthhub_small_clean/`](data/healthhub_small_clean): contains the small subset of Health Hub cleaned data; also stores the embeddings generated from Sentence Transformers in a `parquet` format.

- [`notebooks/`](notebooks): contains the exploratory/experimental code where bulk of the logic is implemented

    * [`logger.py`](notebooks/logger.py): contains the code for logging

    * [`preprocess.ipynb`](notebooks/preprocess.ipynb): contains the code for preprocessing the raw data; cleaned output will be stored in [`healthhub_small_clean/`](data/healthhub_small_clean); only needed to run once

    * [`embeddings.ipynb`](notebooks/embeddings.ipynb): contains the code for generating embeddings; embeddings will be stored in [`healthhub_small_clean/`](data/healthhub_small_clean)

    * [`similarity.ipynb`](notebooks/similarity.ipynb): contains the code for calculating similarity between embeddings

    * [`runner.ipynb`](notebooks/runner.ipynb): contains the code for running the notebooks — [`embeddings.ipynb`](notebooks/embeddings.ipynb) and [`similarity.ipynb`](notebooks/similarity.ipynb); parameterize by [`papermill`](https://papermill.readthedocs.io/en/latest/); this notebook helps you run your experiments for different models and pooling strategies and evaluate the results in the `artifacts/` folder

    * [`emb_sim_statistical.ipynb`](notebooks/emb_sim_statistical.ipynb): contains the code for generating embeddings from Statistical Vector-based Embeddings (SVE) techniques and calculating the similarity between embeddings

    * [`runner_statistical.ipynb`](notebooks/runner_statistical.ipynb): contains the code for running the notebook — [`emb_sim_statistical.ipynb`](notebooks/emb_sim_statistical.ipynb); parameterize by [`papermill`](https://papermill.readthedocs.io/en/latest/); this notebook helps you run your experiments for different SVE techniques and similarity metrics and evaluate the results in the `artifacts/` folder

## Usage

To run the notebooks, you can use the [`runner.ipynb`](notebooks/runner.ipynb) or [`runner_statistical.ipynb`](notebooks/runner_statistical.ipynb):

```python
# runner.ipynb

import papermill as pm
from logger import logger

pm.inspect_notebook("<INPUT_NOTEBOOK>")  # inspects and outputs the notebook's parameters 

pm.execute_notebook(
    input_path="<INPUT_NOTEBOOK>",  # input notebook path
    output_path="<OUTPUT_NOTEBOOK>",  # input notebook path
    parameters={...},  # parameters to be passed to the notebook in a dictionary
```

